# Instructions ----
#' This file follows the format generated by FIMS:::use_testthat_template().
#' Necessary tests include input and output (IO) correctness [IO
#' correctness], edge-case handling [Edge handling], and built-in errors and
#' warnings [Error handling]. See `?FIMS:::use_testthat_template` for more
#' information. Every test should have a @description tag that takes up just
#' one line, which will be used in the bookdown report of {testthat} results.

# Deterministic test ----
## Setup ----
# Load necessary data for the integration test
load(test_path("fixtures", "integration_test_data.RData"))

# Set the iteration ID to 1 for accessing specific input/output list
iter_id <- 1

# Run FIMS without wrappers
result <- setup_and_run_FIMS_without_wrappers(
  iter_id = iter_id,
  om_input_list = om_input_list,
  om_output_list = om_output_list,
  em_input_list = em_input_list,
  estimation_mode = FALSE,
  random_effects = c(recruitment = "log_devs")
)

## IO correctness ----
test_that("deterministic run works with correct inputs", {
  # Compare FIMS results with model comparison project OM values
  verify_fims_deterministic(
    report = result[["report"]],
    estimates = result[["sdr_fixed"]],
    om_input = om_input_list[[iter_id]],
    om_output = om_output_list[[iter_id]],
    em_input = em_input_list[[iter_id]],
    use_fimsfit = FALSE
  )
})

test_that("deterministic run returns correct nlls", {
  #' Compare FIMS NLLs with model comparison project "true" NLLs
  verify_fims_nll(
    report = result[["report"]],
    om_input = om_input_list[[iter_id]],
    om_output = om_output_list[[iter_id]],
    em_input = em_input_list[[iter_id]]
  )
})

test_that("check number of parameters and random effects", {
  # TODO: add a test description using the #' @description tag
  expect_equal(length(result[["obj"]][["par"]]), 49)
  # TODO: add a test description using the #' @description tag
  expect_equal(length(result[["obj"]][["env"]][["random"]]), 29)
})


## Edge handling ----
# No edge cases to test.

## Error handling ----
# No built-in errors to test.

# Estimation test ----
## Setup ----
result_log_devs <- setup_and_run_FIMS_without_wrappers(
  iter_id = iter_id,
  om_input_list = om_input_list,
  om_output_list = om_output_list,
  em_input_list = em_input_list,
  estimation_mode = TRUE,
  random_effects = c(recruitment = "log_devs")
)
result_log_r <- setup_and_run_FIMS_without_wrappers(
  iter_id = iter_id,
  om_input_list = om_input_list,
  om_output_list = om_output_list,
  em_input_list = em_input_list,
  estimation_mode = TRUE,
  random_effects = c(recruitment = "log_r")
)

## IO correctness ----
# Compare FIMS results with model comparison project OM values
test_that("estimation test with recruitment re on log devs", {
  # Compare FIMS results with model comparison project OM values
  # Tests currently don't pass when log devs are estimated
  testthat::skip()
  validate_fims(
    report = result_log_devs[["report"]],
    estimates = result_log_devs[["sdr_report"]],
    om_input = om_input_list[[iter_id]],
    om_output = om_output_list[[iter_id]],
    em_input = em_input_list[[iter_id]]
  )
})

test_that("estimation test with recruitment re on logr", {
  # Compare FIMS results with model comparison project OM values
    # Tests currently don't pass when log devs are estimated
  testthat::skip()
  validate_fims(
    report = result_log_r[["report"]],
    estimates = result_log_r[["sdr_report"]],
    om_input = om_input_list[[iter_id]],
    om_output = om_output_list[[iter_id]],
    em_input = em_input_list[[iter_id]]
  )

  # TODO: add a test description using the #' @description tag
  expect_equal(result_log_r$report[["nll_components"]], result_log_devs$report[["nll_components"]], tolerance = 1e-4)
  # TODO: add a test description using the #' @description tag
  expect_equal(result_log_r$report[["recruitment"]], result_log_devs$report[["recruitment"]], tolerance = 1e-4)

  clear()
})
