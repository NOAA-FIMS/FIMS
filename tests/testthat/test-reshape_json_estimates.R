# Instructions ----
#' This file follows the format generated by FIMS:::use_testthat_template().
#' Necessary tests include input and output (IO) correctness [IO
#' correctness], edge-case handling [Edge handling], and built-in errors and
#' warnings [Error handling]. See `?FIMS:::use_testthat_template` for more
#' information. Every test should have a @description tag, which can span
#' multiple lines, that will be used in the bookdown report of the results from
#' {testthat}.

# reshape_json_estimates ----
## Setup ----
# Load or prepare any necessary data for testing
if (!file.exists(test_path("fixtures", "fit_age_length_comp.RDS"))) {
  prepare_test_data()
}

#' Helper function to compare parameter summaries from TMB and JSON sources.
#'
#' @description This function reads a saved FIMS model fit object, processes its
#' TMB and JSON components to extract parameter names and labels, and then
#' compares them for consistency. It also checks for duplicate parameter IDs in
#' the JSON output.
#' @param model_fit_path A character string specifying the path to the .RDS file
#'   containing the model fit object.
#' @return Invisible `NULL` if tests pass. Throws an error via `cli::cli_abort`
#'   if the checks fail.
compare_tmb_and_json_outputs <- function(model_fit_path) {
  # Load the model fit object from the provided path.
  fit <- readRDS(model_fit_path)
  # Extract the core TMB components (object, sdreport, optimization result)
  # from the fit object.
  obj <- get_obj(fit)
  sdreport <- get_sdreport(fit)
  opt <- get_opt(fit)
  parameter_names <- get_obj(fit)[["par"]] |>
    names()

  # Reshape the TMB output into a standardized data frame.
  # This serves as the "expected" result to compare against.
  tmb_output <- FIMS:::reshape_tmb_estimates(
    obj = obj,
    sdreport = sdreport,
    opt = opt,
    parameter_names = parameter_names
  ) |>
    # Select only the columns needed for the comparison to ensure a clean test.
    dplyr::select(
      module_name, label
    ) |>
    # Remove any duplicate rows.
    dplyr::distinct() |>
    # TODO: The test fails for fit objects from estimation runs because the TMB
    # output includes the label "log_r," which is not present in the JSON output.
    # For now, manually remove `log_r` here and create a new issue to track this.
    dplyr::filter(label != "log_r")

  # Extract the model_output, which contains the JSON-like structure.
  model_output <- get_model_output(fit)
  # Reshape the output from the JSON structure into a data frame.
  json_output <- reshape_json_estimates(model_output)

  # Check for any duplicated parameter_id entries in the JSON output, which
  # would indicate a problem in the reshaping logic.
  # Use a tryCatch block to provide a more informative error message if the
  # comparison using testthat::expect_equal fails.
  duplicated_parameter_ids <- json_output |>
    dplyr::count(parameter_id) |>
    # TODO: check if we need to exclude -999
    dplyr::filter(n > 1 & !is.na(parameter_id))

  tryCatch(
    {
      #' @description Test that [reshape_json_estimates()] does not produce
      #' duplicated `parameter_id`s.
      expect_equal(nrow(duplicated_parameter_ids), 0)
    },
    error = function(e) {
      cli::cli_abort(
        c(
          "x" = "There are duplicated `parameter_id`s in the JSON output!",
          "i" = "The duplicated `parameter_id`s are: {.val {duplicated_parameter_ids[['parameter_id']]}}",
          "i" = "The data been used is: {.val {model_fit_path}}",
          "!" = "Original error: {.emph {e$message}}"
        ),
        .call = NULL
      )
    }
  )

  # Compare the structure of the JSON output against the TMB output.
  # Prepare the JSON summary for comparison by selecting, filtering, and sorting
  # it in the same way as the TMB summary.
  json_output <- json_output |>
    dplyr::select(module_name, label) |>
    dplyr::distinct()

  # Find module names that are present in TMB output but missing in JSON output.
  # anti_join() returns rows in the first data frame that do not have a match
  # in the second data frame based on the specified column.
  missing_module_name_in_json <- dplyr::anti_join(
    tmb_output |>
      dplyr::filter(!is.na(module_name)) |>
      dplyr::select(module_name),
    json_output |>
      dplyr::select(module_name)
  )


  # Find labels that are present in TMB output but missing in JSON output.
  missing_label_in_json <- dplyr::anti_join(
    tmb_output |>
      dplyr::select(label),
    json_output |>
      dplyr::select(label)
  )

  # Wrapping the test in tryCatch() allows us to provide
  # a more user-friendly and informative error message.
  tryCatch(
    {
      #' @description Test that all `module_name` values in the TMB output
      #' are found in the JSON output for a given model fit.
      expect_equal(nrow(missing_module_name_in_json), 0)
    },
    error = function(e) {
      cli::cli_abort(
        c(
          "x" = "`module_name` from TMB output is missing in the JSON output!",
          "i" = "Missing `module_name`s: {.val {missing_module_name_in_json}}",
          "i" = "Model fit object: {.val {model_fit_path}}",
          "!" = "Original error: {.emph {e$message}}"
        ),
        .call = NULL
      )
    }
  )

  tryCatch(
    {
      #' @description Test that all `label` values in the TMB output
      #' are found in the JSON output for a given model fit.
      expect_equal(nrow(missing_label_in_json), 0)
    },
    error = function(e) {
      cli::cli_abort(
        c(
          "x" = "`label` from TMB output is missing in the JSON output!",
          "i" = "Missing `label`s: {.val {missing_label_in_json}}",
          "i" = "Model fit object: {.val {model_fit_path}}",
          "!" = "Original error: {.emph {e$message}}"
        ),
        .call = NULL
      )
    }
  )
}

## IO correctness ----
test_that("reshape_json_estimates() output matches TMB for a deterministic run", {
  # Define the path to the deterministic model run fixture.
  deterministic_path <- test_path(
    "fixtures",
    "deterministic_age_length_comp.RDS"
  )
  # Run the comparison function, which will throw an error if checks fail.
  compare_tmb_and_json_outputs(deterministic_path)
})

test_that("reshape_json_estimates() output matches TMB for an estimation run", {
  # Load the test data from an RDS file containing model fits.
  # List all RDS files in the fixtures directory that match the pattern "fit_*.RDS"
  fit_files <- list.files(
    path = test_path("fixtures"),
    pattern = "^fit.*\\.RDS$",
    full.names = TRUE
  )

  # Use purrr::map to apply the function to each file
  result <- purrr::map(fit_files, compare_tmb_and_json_outputs)
})
## Edge handling ----
# No edge cases are being tested.

## Error handling ----
# Please remove/comment out the test template below if there are no built-in errors/warnings.
# No built-in errors to test.
